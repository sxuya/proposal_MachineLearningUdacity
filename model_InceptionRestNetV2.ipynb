{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"all.zip\", 'r')\n",
    "zip_ref.extractall(\".\")\n",
    "zip_ref.close()\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"train.zip\", 'r')\n",
    "zip_ref.extractall(\".\")\n",
    "zip_ref = zipfile.ZipFile(\"test.zip\", 'r')\n",
    "zip_ref.extractall(\".\")\n",
    "zip_ref.close()\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "train_filenames = os.listdir('train')\n",
    "train_cat = filter(lambda x:x[:3] == 'cat', train_filenames)\n",
    "train_dog = filter(lambda x:x[:3] == 'dog', train_filenames)\n",
    "\n",
    "def rmrf_mkdir(dirname):\n",
    "    if os.path.exists(dirname):\n",
    "        shutil.rmtree(dirname)\n",
    "    os.mkdir(dirname)\n",
    "    \n",
    "rmrf_mkdir('trainRun')\n",
    "os.mkdir('trainRun/cat')\n",
    "os.mkdir('trainRun/dog')\n",
    "\n",
    "rmrf_mkdir('testRun')\n",
    "os.symlink('../test/', 'testRun/test')\n",
    "\n",
    "for filename in train_cat:\n",
    "    os.symlink('../../train/'+filename, 'trainRun/cat/'+filename)\n",
    "\n",
    "for filename in train_dog:\n",
    "    os.symlink('../../train/'+filename, 'trainRun/dog/'+filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import h5py\n",
    "\n",
    "base_model = InceptionResNetV2(weights='imagenet', include_top=False)\n",
    "model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "img_width, img_height = 299, 299\n",
    "train_datagen = image.ImageDataGenerator(shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = image.ImageDataGenerator()\n",
    "train_generator = train_datagen.flow_from_directory(\"trainRun\", target_size=(img_height, img_width), shuffle=False, batch_size=16)\n",
    "test_generator = test_datagen.flow_from_directory(\"testRun\", target_size=(img_height, img_width), shuffle=False, batch_size=16, class_mode=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_h5py = model.predict_generator(train_generator)\n",
    "test_h5py = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(\"init_weights_InceptionRestNetV2.h5\") as h:\n",
    "        h.create_dataset(\"train\", data=train_h5py)\n",
    "        h.create_dataset(\"test\", data=test_h5py)\n",
    "        h.create_dataset(\"label\", data=train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(2017)\n",
    "\n",
    "X_train = []\n",
    "X_test = []\n",
    "\n",
    "with h5py.File(\"init_weights_InceptionRestNetV2.h5\", 'r') as h:\n",
    "    X_train.append(np.array(h['train']))\n",
    "    X_test.append(np.array(h['test']))\n",
    "    y_train = np.array(h['label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dropout, Dense\n",
    "np.random.seed(2017)\n",
    "\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = Dropout(0.5)(input_tensor)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model_run = Model(input_tensor, x)\n",
    "\n",
    "model_run.compile(optimizer='adadelta',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/8\n",
      "20000/20000 [==============================] - 3s 139us/step - loss: 7.9308 - acc: 0.4979 - val_loss: 7.9688 - val_acc: 0.5056\n",
      "Epoch 2/8\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 8.0072 - acc: 0.4930 - val_loss: 8.0605 - val_acc: 0.4944\n",
      "Epoch 3/8\n",
      "20000/20000 [==============================] - 1s 34us/step - loss: 7.8586 - acc: 0.5020 - val_loss: 8.0605 - val_acc: 0.4944\n",
      "Epoch 4/8\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 7.8004 - acc: 0.5064 - val_loss: 8.0605 - val_acc: 0.4944\n",
      "Epoch 5/8\n",
      "20000/20000 [==============================] - 1s 34us/step - loss: 7.9662 - acc: 0.4969 - val_loss: 7.9688 - val_acc: 0.5056\n",
      "Epoch 6/8\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 7.8433 - acc: 0.5048 - val_loss: 7.9688 - val_acc: 0.5056\n",
      "Epoch 7/8\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 7.8009 - acc: 0.5101 - val_loss: 7.9688 - val_acc: 0.5056\n",
      "Epoch 8/8\n",
      "20000/20000 [==============================] - 1s 33us/step - loss: 7.9246 - acc: 0.4998 - val_loss: 7.9688 - val_acc: 0.5056\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efbcc9bacf8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_run.fit(X_train, y_train, batch_size=128, nb_epoch=8, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 1s 44us/step\n",
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:17: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1    1.0\n",
       "1   2    1.0\n",
       "2   3    1.0\n",
       "3   4    1.0\n",
       "4   5    1.0\n",
       "5   6    1.0\n",
       "6   7    1.0\n",
       "7   8    1.0\n",
       "8   9    1.0\n",
       "9  10    1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_run.predict(X_test, verbose=1)\n",
    "# y_pred = y_pred.clip(min=0.003, max=0.997)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "test_run_datagen = image.ImageDataGenerator()\n",
    "test_run_generator = test_run_datagen.flow_from_directory(\"testRun\", \n",
    "                                                          (img_height, img_width), \n",
    "                                                         shuffle=False, \n",
    "                                                         batch_size=16, \n",
    "                                                         class_mode=None)\n",
    "\n",
    "for i, fname in enumerate(test_run_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('pred_IceRNV2.csv', index=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
