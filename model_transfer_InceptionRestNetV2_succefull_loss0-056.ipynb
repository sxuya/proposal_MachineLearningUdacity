{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"all.zip\", 'r')\n",
    "zip_ref.extractall(\".\")\n",
    "zip_ref.close()\n",
    "\n",
    "zip_ref = zipfile.ZipFile(\"train.zip\", 'r')\n",
    "zip_ref.extractall(\".\")\n",
    "zip_ref = zipfile.ZipFile(\"test.zip\", 'r')\n",
    "zip_ref.extractall(\".\")\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, GlobalAveragePooling2D, Dropout, Lambda\n",
    "from keras.applications import inception_resnet_v2\n",
    "# from keras.preprocessing.image import *\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:09<00:00, 180.28it/s]\n"
     ]
    }
   ],
   "source": [
    "n = 25000\n",
    "img_height, img_width = 299, 299\n",
    "X = np.zeros((n, img_height, img_width, 3), dtype=np.uint8)\n",
    "y = np.zeros((n, 1), dtype=np.uint8)\n",
    "\n",
    "for i in tqdm(range(12500)): # n/2\n",
    "    X[i] = cv2.resize(cv2.imread('train/cat.%d.jpg' % i), (img_height, img_width))\n",
    "    X[i+12500] = cv2.resize(cv2.imread('train/dog.%d.jpg' % i), (img_height, img_width)) # n/2\n",
    "\n",
    "y[12500:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_input_tensor = Input((img_height, img_width, 3))\n",
    "# x_input_tensor = inception_resnet_v2.preprocess_input(i_input_tensor)\t# 错误的处理\n",
    "x_input_tensor = Lambda(inception_resnet_v2.preprocess_input)(i_input_tensor)\n",
    "\n",
    "base_model = inception_resnet_v2.InceptionResNetV2(input_tensor=x_input_tensor, weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in base_model.layers:\n",
    "    layers.trainable = False\n",
    "\n",
    "i_output = GlobalAveragePooling2D()(base_model.output)\n",
    "i_output = Dropout(0.25)(i_output) # 0.25 比 0.5 好\n",
    "i_predictions = Dense(1, activation='sigmoid')(i_output)\n",
    "model = Model(base_model.input, i_predictions)\n",
    "\n",
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/8\n",
      "20000/20000 [==============================] - 137s 7ms/step - loss: 0.1408 - acc: 0.9530 - val_loss: 0.0722 - val_acc: 0.9788\n",
      "Epoch 2/8\n",
      "20000/20000 [==============================] - 128s 6ms/step - loss: 0.0879 - acc: 0.9671 - val_loss: 0.0711 - val_acc: 0.9798\n",
      "Epoch 3/8\n",
      "20000/20000 [==============================] - 128s 6ms/step - loss: 0.0866 - acc: 0.9677 - val_loss: 0.0807 - val_acc: 0.9762\n",
      "Epoch 4/8\n",
      "20000/20000 [==============================] - 128s 6ms/step - loss: 0.0827 - acc: 0.9692 - val_loss: 0.0766 - val_acc: 0.9778\n",
      "Epoch 5/8\n",
      "20000/20000 [==============================] - 128s 6ms/step - loss: 0.0763 - acc: 0.9707 - val_loss: 0.0559 - val_acc: 0.9872\n",
      "Epoch 6/8\n",
      "20000/20000 [==============================] - 128s 6ms/step - loss: 0.0755 - acc: 0.9716 - val_loss: 0.0696 - val_acc: 0.9820\n",
      "Epoch 7/8\n",
      "20000/20000 [==============================] - 128s 6ms/step - loss: 0.0731 - acc: 0.9723 - val_loss: 0.0640 - val_acc: 0.9844\n",
      "Epoch 8/8\n",
      "20000/20000 [==============================] - 128s 6ms/step - loss: 0.0750 - acc: 0.9719 - val_loss: 0.0617 - val_acc: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3d041674a8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=20,     # defalt 16\n",
    "\tepochs=8, \t# defalt 5\n",
    "\tvalidation_data=(X_valid, y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_1 0\n",
      "lambda_1 1\n",
      "conv2d_1 2\n",
      "batch_normalization_1 3\n",
      "activation_1 4\n",
      "conv2d_2 5\n",
      "batch_normalization_2 6\n",
      "activation_2 7\n",
      "conv2d_3 8\n",
      "batch_normalization_3 9\n",
      "activation_3 10\n",
      "max_pooling2d_1 11\n",
      "conv2d_4 12\n",
      "batch_normalization_4 13\n",
      "activation_4 14\n",
      "conv2d_5 15\n",
      "batch_normalization_5 16\n",
      "activation_5 17\n",
      "max_pooling2d_2 18\n",
      "conv2d_9 19\n",
      "batch_normalization_9 20\n",
      "activation_9 21\n",
      "conv2d_7 22\n",
      "conv2d_10 23\n",
      "batch_normalization_7 24\n",
      "batch_normalization_10 25\n",
      "activation_7 26\n",
      "activation_10 27\n",
      "average_pooling2d_1 28\n",
      "conv2d_6 29\n",
      "conv2d_8 30\n",
      "conv2d_11 31\n",
      "conv2d_12 32\n",
      "batch_normalization_6 33\n",
      "batch_normalization_8 34\n",
      "batch_normalization_11 35\n",
      "batch_normalization_12 36\n",
      "activation_6 37\n",
      "activation_8 38\n",
      "activation_11 39\n",
      "activation_12 40\n",
      "mixed_5b 41\n",
      "conv2d_16 42\n",
      "batch_normalization_16 43\n",
      "activation_16 44\n",
      "conv2d_14 45\n",
      "conv2d_17 46\n",
      "batch_normalization_14 47\n",
      "batch_normalization_17 48\n",
      "activation_14 49\n",
      "activation_17 50\n",
      "conv2d_13 51\n",
      "conv2d_15 52\n",
      "conv2d_18 53\n",
      "batch_normalization_13 54\n",
      "batch_normalization_15 55\n",
      "batch_normalization_18 56\n",
      "activation_13 57\n",
      "activation_15 58\n",
      "activation_18 59\n",
      "block35_1_mixed 60\n",
      "block35_1_conv 61\n",
      "block35_1 62\n",
      "block35_1_ac 63\n",
      "conv2d_22 64\n",
      "batch_normalization_22 65\n",
      "activation_22 66\n",
      "conv2d_20 67\n",
      "conv2d_23 68\n",
      "batch_normalization_20 69\n",
      "batch_normalization_23 70\n",
      "activation_20 71\n",
      "activation_23 72\n",
      "conv2d_19 73\n",
      "conv2d_21 74\n",
      "conv2d_24 75\n",
      "batch_normalization_19 76\n",
      "batch_normalization_21 77\n",
      "batch_normalization_24 78\n",
      "activation_19 79\n",
      "activation_21 80\n",
      "activation_24 81\n",
      "block35_2_mixed 82\n",
      "block35_2_conv 83\n",
      "block35_2 84\n",
      "block35_2_ac 85\n",
      "conv2d_28 86\n",
      "batch_normalization_28 87\n",
      "activation_28 88\n",
      "conv2d_26 89\n",
      "conv2d_29 90\n",
      "batch_normalization_26 91\n",
      "batch_normalization_29 92\n",
      "activation_26 93\n",
      "activation_29 94\n",
      "conv2d_25 95\n",
      "conv2d_27 96\n",
      "conv2d_30 97\n",
      "batch_normalization_25 98\n",
      "batch_normalization_27 99\n",
      "batch_normalization_30 100\n",
      "activation_25 101\n",
      "activation_27 102\n",
      "activation_30 103\n",
      "block35_3_mixed 104\n",
      "block35_3_conv 105\n",
      "block35_3 106\n",
      "block35_3_ac 107\n",
      "conv2d_34 108\n",
      "batch_normalization_34 109\n",
      "activation_34 110\n",
      "conv2d_32 111\n",
      "conv2d_35 112\n",
      "batch_normalization_32 113\n",
      "batch_normalization_35 114\n",
      "activation_32 115\n",
      "activation_35 116\n",
      "conv2d_31 117\n",
      "conv2d_33 118\n",
      "conv2d_36 119\n",
      "batch_normalization_31 120\n",
      "batch_normalization_33 121\n",
      "batch_normalization_36 122\n",
      "activation_31 123\n",
      "activation_33 124\n",
      "activation_36 125\n",
      "block35_4_mixed 126\n",
      "block35_4_conv 127\n",
      "block35_4 128\n",
      "block35_4_ac 129\n",
      "conv2d_40 130\n",
      "batch_normalization_40 131\n",
      "activation_40 132\n",
      "conv2d_38 133\n",
      "conv2d_41 134\n",
      "batch_normalization_38 135\n",
      "batch_normalization_41 136\n",
      "activation_38 137\n",
      "activation_41 138\n",
      "conv2d_37 139\n",
      "conv2d_39 140\n",
      "conv2d_42 141\n",
      "batch_normalization_37 142\n",
      "batch_normalization_39 143\n",
      "batch_normalization_42 144\n",
      "activation_37 145\n",
      "activation_39 146\n",
      "activation_42 147\n",
      "block35_5_mixed 148\n",
      "block35_5_conv 149\n",
      "block35_5 150\n",
      "block35_5_ac 151\n",
      "conv2d_46 152\n",
      "batch_normalization_46 153\n",
      "activation_46 154\n",
      "conv2d_44 155\n",
      "conv2d_47 156\n",
      "batch_normalization_44 157\n",
      "batch_normalization_47 158\n",
      "activation_44 159\n",
      "activation_47 160\n",
      "conv2d_43 161\n",
      "conv2d_45 162\n",
      "conv2d_48 163\n",
      "batch_normalization_43 164\n",
      "batch_normalization_45 165\n",
      "batch_normalization_48 166\n",
      "activation_43 167\n",
      "activation_45 168\n",
      "activation_48 169\n",
      "block35_6_mixed 170\n",
      "block35_6_conv 171\n",
      "block35_6 172\n",
      "block35_6_ac 173\n",
      "conv2d_52 174\n",
      "batch_normalization_52 175\n",
      "activation_52 176\n",
      "conv2d_50 177\n",
      "conv2d_53 178\n",
      "batch_normalization_50 179\n",
      "batch_normalization_53 180\n",
      "activation_50 181\n",
      "activation_53 182\n",
      "conv2d_49 183\n",
      "conv2d_51 184\n",
      "conv2d_54 185\n",
      "batch_normalization_49 186\n",
      "batch_normalization_51 187\n",
      "batch_normalization_54 188\n",
      "activation_49 189\n",
      "activation_51 190\n",
      "activation_54 191\n",
      "block35_7_mixed 192\n",
      "block35_7_conv 193\n",
      "block35_7 194\n",
      "block35_7_ac 195\n",
      "conv2d_58 196\n",
      "batch_normalization_58 197\n",
      "activation_58 198\n",
      "conv2d_56 199\n",
      "conv2d_59 200\n",
      "batch_normalization_56 201\n",
      "batch_normalization_59 202\n",
      "activation_56 203\n",
      "activation_59 204\n",
      "conv2d_55 205\n",
      "conv2d_57 206\n",
      "conv2d_60 207\n",
      "batch_normalization_55 208\n",
      "batch_normalization_57 209\n",
      "batch_normalization_60 210\n",
      "activation_55 211\n",
      "activation_57 212\n",
      "activation_60 213\n",
      "block35_8_mixed 214\n",
      "block35_8_conv 215\n",
      "block35_8 216\n",
      "block35_8_ac 217\n",
      "conv2d_64 218\n",
      "batch_normalization_64 219\n",
      "activation_64 220\n",
      "conv2d_62 221\n",
      "conv2d_65 222\n",
      "batch_normalization_62 223\n",
      "batch_normalization_65 224\n",
      "activation_62 225\n",
      "activation_65 226\n",
      "conv2d_61 227\n",
      "conv2d_63 228\n",
      "conv2d_66 229\n",
      "batch_normalization_61 230\n",
      "batch_normalization_63 231\n",
      "batch_normalization_66 232\n",
      "activation_61 233\n",
      "activation_63 234\n",
      "activation_66 235\n",
      "block35_9_mixed 236\n",
      "block35_9_conv 237\n",
      "block35_9 238\n",
      "block35_9_ac 239\n",
      "conv2d_70 240\n",
      "batch_normalization_70 241\n",
      "activation_70 242\n",
      "conv2d_68 243\n",
      "conv2d_71 244\n",
      "batch_normalization_68 245\n",
      "batch_normalization_71 246\n",
      "activation_68 247\n",
      "activation_71 248\n",
      "conv2d_67 249\n",
      "conv2d_69 250\n",
      "conv2d_72 251\n",
      "batch_normalization_67 252\n",
      "batch_normalization_69 253\n",
      "batch_normalization_72 254\n",
      "activation_67 255\n",
      "activation_69 256\n",
      "activation_72 257\n",
      "block35_10_mixed 258\n",
      "block35_10_conv 259\n",
      "block35_10 260\n",
      "block35_10_ac 261\n",
      "conv2d_74 262\n",
      "batch_normalization_74 263\n",
      "activation_74 264\n",
      "conv2d_75 265\n",
      "batch_normalization_75 266\n",
      "activation_75 267\n",
      "conv2d_73 268\n",
      "conv2d_76 269\n",
      "batch_normalization_73 270\n",
      "batch_normalization_76 271\n",
      "activation_73 272\n",
      "activation_76 273\n",
      "max_pooling2d_3 274\n",
      "mixed_6a 275\n",
      "conv2d_78 276\n",
      "batch_normalization_78 277\n",
      "activation_78 278\n",
      "conv2d_79 279\n",
      "batch_normalization_79 280\n",
      "activation_79 281\n",
      "conv2d_77 282\n",
      "conv2d_80 283\n",
      "batch_normalization_77 284\n",
      "batch_normalization_80 285\n",
      "activation_77 286\n",
      "activation_80 287\n",
      "block17_1_mixed 288\n",
      "block17_1_conv 289\n",
      "block17_1 290\n",
      "block17_1_ac 291\n",
      "conv2d_82 292\n",
      "batch_normalization_82 293\n",
      "activation_82 294\n",
      "conv2d_83 295\n",
      "batch_normalization_83 296\n",
      "activation_83 297\n",
      "conv2d_81 298\n",
      "conv2d_84 299\n",
      "batch_normalization_81 300\n",
      "batch_normalization_84 301\n",
      "activation_81 302\n",
      "activation_84 303\n",
      "block17_2_mixed 304\n",
      "block17_2_conv 305\n",
      "block17_2 306\n",
      "block17_2_ac 307\n",
      "conv2d_86 308\n",
      "batch_normalization_86 309\n",
      "activation_86 310\n",
      "conv2d_87 311\n",
      "batch_normalization_87 312\n",
      "activation_87 313\n",
      "conv2d_85 314\n",
      "conv2d_88 315\n",
      "batch_normalization_85 316\n",
      "batch_normalization_88 317\n",
      "activation_85 318\n",
      "activation_88 319\n",
      "block17_3_mixed 320\n",
      "block17_3_conv 321\n",
      "block17_3 322\n",
      "block17_3_ac 323\n",
      "conv2d_90 324\n",
      "batch_normalization_90 325\n",
      "activation_90 326\n",
      "conv2d_91 327\n",
      "batch_normalization_91 328\n",
      "activation_91 329\n",
      "conv2d_89 330\n",
      "conv2d_92 331\n",
      "batch_normalization_89 332\n",
      "batch_normalization_92 333\n",
      "activation_89 334\n",
      "activation_92 335\n",
      "block17_4_mixed 336\n",
      "block17_4_conv 337\n",
      "block17_4 338\n",
      "block17_4_ac 339\n",
      "conv2d_94 340\n",
      "batch_normalization_94 341\n",
      "activation_94 342\n",
      "conv2d_95 343\n",
      "batch_normalization_95 344\n",
      "activation_95 345\n",
      "conv2d_93 346\n",
      "conv2d_96 347\n",
      "batch_normalization_93 348\n",
      "batch_normalization_96 349\n",
      "activation_93 350\n",
      "activation_96 351\n",
      "block17_5_mixed 352\n",
      "block17_5_conv 353\n",
      "block17_5 354\n",
      "block17_5_ac 355\n",
      "conv2d_98 356\n",
      "batch_normalization_98 357\n",
      "activation_98 358\n",
      "conv2d_99 359\n",
      "batch_normalization_99 360\n",
      "activation_99 361\n",
      "conv2d_97 362\n",
      "conv2d_100 363\n",
      "batch_normalization_97 364\n",
      "batch_normalization_100 365\n",
      "activation_97 366\n",
      "activation_100 367\n",
      "block17_6_mixed 368\n",
      "block17_6_conv 369\n",
      "block17_6 370\n",
      "block17_6_ac 371\n",
      "conv2d_102 372\n",
      "batch_normalization_102 373\n",
      "activation_102 374\n",
      "conv2d_103 375\n",
      "batch_normalization_103 376\n",
      "activation_103 377\n",
      "conv2d_101 378\n",
      "conv2d_104 379\n",
      "batch_normalization_101 380\n",
      "batch_normalization_104 381\n",
      "activation_101 382\n",
      "activation_104 383\n",
      "block17_7_mixed 384\n",
      "block17_7_conv 385\n",
      "block17_7 386\n",
      "block17_7_ac 387\n",
      "conv2d_106 388\n",
      "batch_normalization_106 389\n",
      "activation_106 390\n",
      "conv2d_107 391\n",
      "batch_normalization_107 392\n",
      "activation_107 393\n",
      "conv2d_105 394\n",
      "conv2d_108 395\n",
      "batch_normalization_105 396\n",
      "batch_normalization_108 397\n",
      "activation_105 398\n",
      "activation_108 399\n",
      "block17_8_mixed 400\n",
      "block17_8_conv 401\n",
      "block17_8 402\n",
      "block17_8_ac 403\n",
      "conv2d_110 404\n",
      "batch_normalization_110 405\n",
      "activation_110 406\n",
      "conv2d_111 407\n",
      "batch_normalization_111 408\n",
      "activation_111 409\n",
      "conv2d_109 410\n",
      "conv2d_112 411\n",
      "batch_normalization_109 412\n",
      "batch_normalization_112 413\n",
      "activation_109 414\n",
      "activation_112 415\n",
      "block17_9_mixed 416\n",
      "block17_9_conv 417\n",
      "block17_9 418\n",
      "block17_9_ac 419\n",
      "conv2d_114 420\n",
      "batch_normalization_114 421\n",
      "activation_114 422\n",
      "conv2d_115 423\n",
      "batch_normalization_115 424\n",
      "activation_115 425\n",
      "conv2d_113 426\n",
      "conv2d_116 427\n",
      "batch_normalization_113 428\n",
      "batch_normalization_116 429\n",
      "activation_113 430\n",
      "activation_116 431\n",
      "block17_10_mixed 432\n",
      "block17_10_conv 433\n",
      "block17_10 434\n",
      "block17_10_ac 435\n",
      "conv2d_118 436\n",
      "batch_normalization_118 437\n",
      "activation_118 438\n",
      "conv2d_119 439\n",
      "batch_normalization_119 440\n",
      "activation_119 441\n",
      "conv2d_117 442\n",
      "conv2d_120 443\n",
      "batch_normalization_117 444\n",
      "batch_normalization_120 445\n",
      "activation_117 446\n",
      "activation_120 447\n",
      "block17_11_mixed 448\n",
      "block17_11_conv 449\n",
      "block17_11 450\n",
      "block17_11_ac 451\n",
      "conv2d_122 452\n",
      "batch_normalization_122 453\n",
      "activation_122 454\n",
      "conv2d_123 455\n",
      "batch_normalization_123 456\n",
      "activation_123 457\n",
      "conv2d_121 458\n",
      "conv2d_124 459\n",
      "batch_normalization_121 460\n",
      "batch_normalization_124 461\n",
      "activation_121 462\n",
      "activation_124 463\n",
      "block17_12_mixed 464\n",
      "block17_12_conv 465\n",
      "block17_12 466\n",
      "block17_12_ac 467\n",
      "conv2d_126 468\n",
      "batch_normalization_126 469\n",
      "activation_126 470\n",
      "conv2d_127 471\n",
      "batch_normalization_127 472\n",
      "activation_127 473\n",
      "conv2d_125 474\n",
      "conv2d_128 475\n",
      "batch_normalization_125 476\n",
      "batch_normalization_128 477\n",
      "activation_125 478\n",
      "activation_128 479\n",
      "block17_13_mixed 480\n",
      "block17_13_conv 481\n",
      "block17_13 482\n",
      "block17_13_ac 483\n",
      "conv2d_130 484\n",
      "batch_normalization_130 485\n",
      "activation_130 486\n",
      "conv2d_131 487\n",
      "batch_normalization_131 488\n",
      "activation_131 489\n",
      "conv2d_129 490\n",
      "conv2d_132 491\n",
      "batch_normalization_129 492\n",
      "batch_normalization_132 493\n",
      "activation_129 494\n",
      "activation_132 495\n",
      "block17_14_mixed 496\n",
      "block17_14_conv 497\n",
      "block17_14 498\n",
      "block17_14_ac 499\n",
      "conv2d_134 500\n",
      "batch_normalization_134 501\n",
      "activation_134 502\n",
      "conv2d_135 503\n",
      "batch_normalization_135 504\n",
      "activation_135 505\n",
      "conv2d_133 506\n",
      "conv2d_136 507\n",
      "batch_normalization_133 508\n",
      "batch_normalization_136 509\n",
      "activation_133 510\n",
      "activation_136 511\n",
      "block17_15_mixed 512\n",
      "block17_15_conv 513\n",
      "block17_15 514\n",
      "block17_15_ac 515\n",
      "conv2d_138 516\n",
      "batch_normalization_138 517\n",
      "activation_138 518\n",
      "conv2d_139 519\n",
      "batch_normalization_139 520\n",
      "activation_139 521\n",
      "conv2d_137 522\n",
      "conv2d_140 523\n",
      "batch_normalization_137 524\n",
      "batch_normalization_140 525\n",
      "activation_137 526\n",
      "activation_140 527\n",
      "block17_16_mixed 528\n",
      "block17_16_conv 529\n",
      "block17_16 530\n",
      "block17_16_ac 531\n",
      "conv2d_142 532\n",
      "batch_normalization_142 533\n",
      "activation_142 534\n",
      "conv2d_143 535\n",
      "batch_normalization_143 536\n",
      "activation_143 537\n",
      "conv2d_141 538\n",
      "conv2d_144 539\n",
      "batch_normalization_141 540\n",
      "batch_normalization_144 541\n",
      "activation_141 542\n",
      "activation_144 543\n",
      "block17_17_mixed 544\n",
      "block17_17_conv 545\n",
      "block17_17 546\n",
      "block17_17_ac 547\n",
      "conv2d_146 548\n",
      "batch_normalization_146 549\n",
      "activation_146 550\n",
      "conv2d_147 551\n",
      "batch_normalization_147 552\n",
      "activation_147 553\n",
      "conv2d_145 554\n",
      "conv2d_148 555\n",
      "batch_normalization_145 556\n",
      "batch_normalization_148 557\n",
      "activation_145 558\n",
      "activation_148 559\n",
      "block17_18_mixed 560\n",
      "block17_18_conv 561\n",
      "block17_18 562\n",
      "block17_18_ac 563\n",
      "conv2d_150 564\n",
      "batch_normalization_150 565\n",
      "activation_150 566\n",
      "conv2d_151 567\n",
      "batch_normalization_151 568\n",
      "activation_151 569\n",
      "conv2d_149 570\n",
      "conv2d_152 571\n",
      "batch_normalization_149 572\n",
      "batch_normalization_152 573\n",
      "activation_149 574\n",
      "activation_152 575\n",
      "block17_19_mixed 576\n",
      "block17_19_conv 577\n",
      "block17_19 578\n",
      "block17_19_ac 579\n",
      "conv2d_154 580\n",
      "batch_normalization_154 581\n",
      "activation_154 582\n",
      "conv2d_155 583\n",
      "batch_normalization_155 584\n",
      "activation_155 585\n",
      "conv2d_153 586\n",
      "conv2d_156 587\n",
      "batch_normalization_153 588\n",
      "batch_normalization_156 589\n",
      "activation_153 590\n",
      "activation_156 591\n",
      "block17_20_mixed 592\n",
      "block17_20_conv 593\n",
      "block17_20 594\n",
      "block17_20_ac 595\n",
      "conv2d_161 596\n",
      "batch_normalization_161 597\n",
      "activation_161 598\n",
      "conv2d_157 599\n",
      "conv2d_159 600\n",
      "conv2d_162 601\n",
      "batch_normalization_157 602\n",
      "batch_normalization_159 603\n",
      "batch_normalization_162 604\n",
      "activation_157 605\n",
      "activation_159 606\n",
      "activation_162 607\n",
      "conv2d_158 608\n",
      "conv2d_160 609\n",
      "conv2d_163 610\n",
      "batch_normalization_158 611\n",
      "batch_normalization_160 612\n",
      "batch_normalization_163 613\n",
      "activation_158 614\n",
      "activation_160 615\n",
      "activation_163 616\n",
      "max_pooling2d_4 617\n",
      "mixed_7a 618\n",
      "conv2d_165 619\n",
      "batch_normalization_165 620\n",
      "activation_165 621\n",
      "conv2d_166 622\n",
      "batch_normalization_166 623\n",
      "activation_166 624\n",
      "conv2d_164 625\n",
      "conv2d_167 626\n",
      "batch_normalization_164 627\n",
      "batch_normalization_167 628\n",
      "activation_164 629\n",
      "activation_167 630\n",
      "block8_1_mixed 631\n",
      "block8_1_conv 632\n",
      "block8_1 633\n",
      "block8_1_ac 634\n",
      "conv2d_169 635\n",
      "batch_normalization_169 636\n",
      "activation_169 637\n",
      "conv2d_170 638\n",
      "batch_normalization_170 639\n",
      "activation_170 640\n",
      "conv2d_168 641\n",
      "conv2d_171 642\n",
      "batch_normalization_168 643\n",
      "batch_normalization_171 644\n",
      "activation_168 645\n",
      "activation_171 646\n",
      "block8_2_mixed 647\n",
      "block8_2_conv 648\n",
      "block8_2 649\n",
      "block8_2_ac 650\n",
      "conv2d_173 651\n",
      "batch_normalization_173 652\n",
      "activation_173 653\n",
      "conv2d_174 654\n",
      "batch_normalization_174 655\n",
      "activation_174 656\n",
      "conv2d_172 657\n",
      "conv2d_175 658\n",
      "batch_normalization_172 659\n",
      "batch_normalization_175 660\n",
      "activation_172 661\n",
      "activation_175 662\n",
      "block8_3_mixed 663\n",
      "block8_3_conv 664\n",
      "block8_3 665\n",
      "block8_3_ac 666\n",
      "conv2d_177 667\n",
      "batch_normalization_177 668\n",
      "activation_177 669\n",
      "conv2d_178 670\n",
      "batch_normalization_178 671\n",
      "activation_178 672\n",
      "conv2d_176 673\n",
      "conv2d_179 674\n",
      "batch_normalization_176 675\n",
      "batch_normalization_179 676\n",
      "activation_176 677\n",
      "activation_179 678\n",
      "block8_4_mixed 679\n",
      "block8_4_conv 680\n",
      "block8_4 681\n",
      "block8_4_ac 682\n",
      "conv2d_181 683\n",
      "batch_normalization_181 684\n",
      "activation_181 685\n",
      "conv2d_182 686\n",
      "batch_normalization_182 687\n",
      "activation_182 688\n",
      "conv2d_180 689\n",
      "conv2d_183 690\n",
      "batch_normalization_180 691\n",
      "batch_normalization_183 692\n",
      "activation_180 693\n",
      "activation_183 694\n",
      "block8_5_mixed 695\n",
      "block8_5_conv 696\n",
      "block8_5 697\n",
      "block8_5_ac 698\n",
      "conv2d_185 699\n",
      "batch_normalization_185 700\n",
      "activation_185 701\n",
      "conv2d_186 702\n",
      "batch_normalization_186 703\n",
      "activation_186 704\n",
      "conv2d_184 705\n",
      "conv2d_187 706\n",
      "batch_normalization_184 707\n",
      "batch_normalization_187 708\n",
      "activation_184 709\n",
      "activation_187 710\n",
      "block8_6_mixed 711\n",
      "block8_6_conv 712\n",
      "block8_6 713\n",
      "block8_6_ac 714\n",
      "conv2d_189 715\n",
      "batch_normalization_189 716\n",
      "activation_189 717\n",
      "conv2d_190 718\n",
      "batch_normalization_190 719\n",
      "activation_190 720\n",
      "conv2d_188 721\n",
      "conv2d_191 722\n",
      "batch_normalization_188 723\n",
      "batch_normalization_191 724\n",
      "activation_188 725\n",
      "activation_191 726\n",
      "block8_7_mixed 727\n",
      "block8_7_conv 728\n",
      "block8_7 729\n",
      "block8_7_ac 730\n",
      "conv2d_193 731\n",
      "batch_normalization_193 732\n",
      "activation_193 733\n",
      "conv2d_194 734\n",
      "batch_normalization_194 735\n",
      "activation_194 736\n",
      "conv2d_192 737\n",
      "conv2d_195 738\n",
      "batch_normalization_192 739\n",
      "batch_normalization_195 740\n",
      "activation_192 741\n",
      "activation_195 742\n",
      "block8_8_mixed 743\n",
      "block8_8_conv 744\n",
      "block8_8 745\n",
      "block8_8_ac 746\n",
      "conv2d_197 747\n",
      "batch_normalization_197 748\n",
      "activation_197 749\n",
      "conv2d_198 750\n",
      "batch_normalization_198 751\n",
      "activation_198 752\n",
      "conv2d_196 753\n",
      "conv2d_199 754\n",
      "batch_normalization_196 755\n",
      "batch_normalization_199 756\n",
      "activation_196 757\n",
      "activation_199 758\n",
      "block8_9_mixed 759\n",
      "block8_9_conv 760\n",
      "block8_9 761\n",
      "block8_9_ac 762\n",
      "conv2d_201 763\n",
      "batch_normalization_201 764\n",
      "activation_201 765\n",
      "conv2d_202 766\n",
      "batch_normalization_202 767\n",
      "activation_202 768\n",
      "conv2d_200 769\n",
      "conv2d_203 770\n",
      "batch_normalization_200 771\n",
      "batch_normalization_203 772\n",
      "activation_200 773\n",
      "activation_203 774\n",
      "block8_10_mixed 775\n",
      "block8_10_conv 776\n",
      "block8_10 777\n",
      "conv_7b 778\n",
      "conv_7b_bn 779\n",
      "conv_7b_ac 780\n",
      "global_average_pooling2d_1 781\n",
      "dropout_1 782\n",
      "dense_1 783\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model.layers)):\n",
    "    print(model.layers[i].name, i)\n",
    "\n",
    "for layer in model.layers[770:]:\t# total 783 layers\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "from keras import optimizers\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/8\n",
      "20000/20000 [==============================] - 138s 7ms/step - loss: 0.0772 - acc: 0.9719 - val_loss: 0.0385 - val_acc: 0.9912\n",
      "Epoch 2/8\n",
      "20000/20000 [==============================] - 131s 7ms/step - loss: 0.0679 - acc: 0.9743 - val_loss: 0.0382 - val_acc: 0.9912\n",
      "Epoch 3/8\n",
      "20000/20000 [==============================] - 131s 7ms/step - loss: 0.0637 - acc: 0.9761 - val_loss: 0.0382 - val_acc: 0.9914\n",
      "Epoch 4/8\n",
      "20000/20000 [==============================] - 131s 7ms/step - loss: 0.0688 - acc: 0.9749 - val_loss: 0.0379 - val_acc: 0.9914\n",
      "Epoch 5/8\n",
      "20000/20000 [==============================] - 131s 7ms/step - loss: 0.0616 - acc: 0.9759 - val_loss: 0.0376 - val_acc: 0.9914\n",
      "Epoch 6/8\n",
      "20000/20000 [==============================] - 131s 7ms/step - loss: 0.0671 - acc: 0.9743 - val_loss: 0.0375 - val_acc: 0.9908\n",
      "Epoch 7/8\n",
      "20000/20000 [==============================] - 131s 7ms/step - loss: 0.0601 - acc: 0.9761 - val_loss: 0.0362 - val_acc: 0.9916\n",
      "Epoch 8/8\n",
      "20000/20000 [==============================] - 131s 7ms/step - loss: 0.0623 - acc: 0.9774 - val_loss: 0.0380 - val_acc: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3d04167c50>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=20, \t# first: 16\n",
    "\tepochs=8, \t# first: 5 \n",
    "\tvalidation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('modelInceptionResNet_transfer_0_07.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12500/12500 [01:48<00:00, 115.07it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.zeros((n, img_height, img_width, 3), dtype=np.uint8)\n",
    "for i in tqdm(range(12500)):\n",
    "    j = i+1\n",
    "    X_test[i] = cv2.resize(cv2.imread('test/%d.jpg' % j), (img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 143s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:5: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "for i in range(12500):\n",
    "\tdf.set_value(i, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('pred_changePredictCsvMethond_180711.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p36]",
   "language": "python",
   "name": "conda-env-tensorflow_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
